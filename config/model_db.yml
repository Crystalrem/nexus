models:
  - framework: darknet # temporary
    model_name: traffic
    type: detection
    yolo_model: yolo-v2-voc
    face_cfg_file: vgg_face_caffe/VGG_FACE_deploy.prototxt
    face_weight_file: vgg_face_caffe/VGG_FACE.caffemodel
    face_mean_value: [99.5503, 115.7630, 151.2761]
    face_class_names: vgg_face_caffe/names.txt
    cars_cfg_file: googlenet_cars/deploy.prototxt
    cars_weight_file: googlenet_cars/googlenet_finetune_web_car_iter_10000.caffemodel
    cars_mean_file: googlenet_cars/imagenet_mean.binaryproto
    cars_class_names: googlenet_cars/make_model_names.txt
  - framework: darknet
    model_name: yolo9000
    type: detection
    class_names: data/9k.names
  - framework: darknet
    model_name: yolo-v2-voc
    type: detection
    class_names: data/voc.names
  - framework: darknet
    model_name: darknet
    type: classification
  - framework: caffe
    model_name: vgg_face
    type: classification
    cfg_file: vgg_face_caffe/VGG_FACE_deploy.prototxt
    weight_file: vgg_face_caffe/VGG_FACE.caffemodel
    class_names: vgg_face_caffe/names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
  - framework: caffe
    model_name: F1 # face recongition
    type: classification
    cfg_file: F1/F1.prototxt
    weight_file: F1/F1.caffemodel
    class_names: F1/names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
  - framework: caffe
    model_name: F1_prefix # face recongition
    type: classification
    cfg_file: F1/F1.prototxt
    weight_file: F1/F1.caffemodel
    class_names: F1/names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
    prefix_layer: drop6
  - framework: caffe
    model_name: F1_msr201 # face recongition
    type: classification
    cfg_file: F1_msr201/F1_msr201.prototxt
    weight_file: F1_msr201/F1_msr201.caffemodel
    class_names: F1_msr201/msr201_names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
  - framework: caffe
    model_name: F2 # face recongition
    type: classification
    cfg_file: F2/F2.prototxt
    weight_file: F2/F2.caffemodel
    class_names: F2/names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
  - framework: caffe
    model_name: F2_prefix # face recongition
    type: classification
    cfg_file: F2/F2.prototxt
    weight_file: F2/F2.caffemodel
    class_names: F2/names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
    prefix_layer: drop6
  - framework: caffe
    model_name: F2_msr201 # face recongition
    type: classification
    cfg_file: F2_msr201/F2_msr201.prototxt
    weight_file: F2_msr201/F2_msr201.caffemodel
    class_names: F2_msr201/msr201_names.txt
    mean_value: [99.5503, 115.7630, 151.2761]
  - framework: caffe
    model_name: vgg_s
    type: classification
    cfg_file: vgg_s/vgg_s.prototxt
    weight_file: vgg_s/vgg_s.caffemodel
    class_names: vgg_s/synset_words.txt
    mean_file: vgg_s/vgg_s_mean.binaryproto
  - framework: caffe
    model_name: vgg_s_prefix
    type: classification
    cfg_file: vgg_s/vgg_s.prototxt
    weight_file: vgg_s/vgg_s.caffemodel
    class_names: vgg_s/synset_words.txt
    mean_file: vgg_s/vgg_s_mean.binaryproto
    prefix_layer: drop7
  - framework: caffe
    model_name: vgg16
    type: classification
    cfg_file: vgg16/1/vgg16.prototxt
    weight_file: vgg16/1/vgg16.caffemodel
    class_names: vgg16/synset_words.txt
    mean_value: [103.939, 116.779, 123.68]
  - framework: caffe
    model_name: googlenet_cars
    type: classification
    cfg_file: googlenet_cars/deploy.prototxt
    weight_file: googlenet_cars/googlenet_finetune_web_car_iter_10000.caffemodel
    class_names: googlenet_cars/make_model_names.txt
    mean_file: googlenet_cars/imagenet_mean.binaryproto
  - framework: caffe
    model_name: densecap
    type: caption
    feature_prototxt: densecap/1/vgg_region_global_feature.prototxt
    rnn_prototxt: densecap/1/test_cap_pred_context.prototxt
    embed_prototxt: densecap/1/test_word_embedding.prototxt
    model_file: densecap/1/dense_cap_late_fusion_sum.caffemodel
    vocab_file: densecap/visual_genome_1.0_vocab.txt
    # default size, aspect ratio 4:3
    image_height: 540
    image_width: 720
    #target_size: 600
    #max_size: 720
    mean_value: [102.9801, 115.9465, 122.7717]
    max_boxes: 300
    max_timestep: 15
    nms_threshold: 0.5
    score_threshold: 0.5
    bbox_mean: [0, 0, 0, 0]
    bbox_stds: [0.1, 0.1, 0.2, 0.2]
  - framework: tensorflow
    model_name: inception_v3
    type: classification
    model_file: inception_v3/inception_v3_2016_08_28_frozen.pb
    class_names: inception_v3/imagenet_slim_labels.txt
    image_height: 299
    image_width: 299
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: InceptionV3/Predictions/Softmax
  - framework: tensorflow
    model_name: mobilenet_v1_1.0_128
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_1.0_128_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 128
    image_width: 128
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.75_128
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.75_128_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 128
    image_width: 128
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.50_128
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.50_128_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 128
    image_width: 128
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.25_128
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.25_128_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 128
    image_width: 128
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_1.0_160
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_1.0_160_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 160
    image_width: 160
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.75_160
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.75_160_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 160
    image_width: 160
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.50_160
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.50_160_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 160
    image_width: 160
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.25_160
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.25_160_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 160
    image_width: 160
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_1.0_192
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_1.0_192_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 192
    image_width: 192
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.75_192
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.75_192_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 192
    image_width: 192
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.50_192
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.50_192_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 192
    image_width: 192
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.25_192
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.25_192_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 192
    image_width: 192
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_1.0_224
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_1.0_224_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 224
    image_width: 224
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.75_224
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.75_224_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 224
    image_width: 224
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.50_224
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.50_224_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 224
    image_width: 224
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
  - framework: tensorflow
    model_name: mobilenet_v1_0.25_224
    type: classification
    model_file: mobilenet_v1/mobilenet_v1_0.25_224_2017_06_14.pb
    class_names: mobilenet_v1/imagenet_slim_labels.txt
    image_height: 224
    image_width: 224
    input_mean: [0, 0, 0]
    input_std: [255, 255, 255]
    input_layer: input
    output_layer: output
